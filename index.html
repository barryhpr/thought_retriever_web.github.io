<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Thought-Retriever: Don't Just Retrieve Raw Data, Retrieve Thoughts</title>

  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Thought-Retriever: Don't Just Retrieve Raw Data, Retrieve Thoughts</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                Tao Feng<sup>1*</sup>,
              </span>
                <span class="author-block">
                  Pengrui Han<sup>1,2*</sup>,
                </span>
                  <span class="author-block">
                    Guanyu Lin<sup>1,3*</sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://www.mit.edu/~geliu/" target="_blank">Ge Liu</a><sup>1</sup>,</span>
                  <span class="author-block">
                    <span class="author-block">
                      <a href="https://cs.stanford.edu/~jiaxuan/" target="_blank">Jiaxuan You</a><sup>1</sup></span>
                    <span class="author-block">
                
                  </div>
             
                  <div class="is-size-5 publication-authors">
                    <span class="author-block">
                      <sup>1</sup>University of Illinois Urbana-Champaign,
                      <sup>2</sup>Carleton College,
                      <sup>3</sup>Carnegie Mellon University,
                    <span class="eql-cntrb"><small><br><sup>*</sup>Equal contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2402.07456.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/OS-Copilot/FRIDAY" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2402.07456" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/videos/excel.mov"
        type="video/mp4">
      </video>

    </div>
  </div>
</section> -->
<section class="section hero">  
  <div class="container is-max-desktop">
    We will replace this with our demo videos 
      <div class="columns is-justify-content-center">
        <div class="column is-6"> <!-- 这里设置为占用一半的宽度 -->
          <!-- <video poster="" id="tree" autoplay controls muted loop height="100%">
            <source src="static/videos/excel.mov" type="video/mp4">
          </video> -->
          <div class="video-container">
            <video poster="" id="video1" autoplay controls muted loop height="100%">
              <source src="static/videos/excel.mov" type="video/mp4">
            </video>
            <p class="has-text-centered"><b>Demo1: Operating Excel Files.</b></p>
          </div>
        </div>
        <div class="column is-6"> <!-- 这里设置为占用一半的宽度 -->
          <video poster="" id="tree" autoplay controls muted loop height="100%">
            <source src="static/videos/react_website.mov" type="video/mp4">
          </video>
          <p class="has-text-centered"><b>Demo2: Creating a Webpage.</b></p>
        </div>
    </div>  
      <div class="columns">  
          <div class="column is-6">
              <div class="video-container">  
                <video poster="" id="tree" autoplay controls muted loop height="100%">
            
                  <source src="static/videos/enter_focused_mode.mov"
                  type="video/mp4">
                </video>
                <p class="has-text-centered"><b>Demo3: Entering Focused Mode.</b></p>
              </div>  
          </div>  
          <div class="column is-6">  
              <div class="video-container">  
                <video poster="" id="tree" autoplay controls muted loop height="100%">
            
                  <source src="static/videos/play_mosic.mov"
                  type="video/mp4">
                </video>
                <p class="has-text-centered"><b>Demo4: Playing Music.</b></p>
              </div>  
       
      </div>
    </div>
      <div>
        <p><b>(Stay tuned! More demos are coming soon~)</b></p>
      </div>  
  </div>  
</section>  

<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Large language models (LLMs) have transformed AI research thanks to their powerful internal capabilities and knowledge. However, existing LLMs still fail to effectively incorporate the massive external knowledge when interacting with the world. Although retrieval-augmented LLMs are proposed to mitigate the issue, they are still fundamentally constrained by the context length of LLMs, as they can only retrieve top-K raw data chunks from the external knowledge base which often consists of millions of data chunks. Here we propose Thought-Retriever, a novel model-agnostic algorithm that helps LLMs generate output conditioned on arbitrarily long external data, without being constrained by the context length or number of retrieved data chunks. Our key insight is to let an LLM fully leverage its intermediate thoughts generated when solving past user queries, organizing them in thought memory, and retrieving the relevant thoughts when addressing new queries. Notably, Thought-Retriever can self-evolve through continuous user interactions thanks to the growing number and depth of thoughts. Besides algorithmic innovation, we further meticulously prepare a novel benchmark, AcademicEval, which requires an LLM to faithfully leverage ultra-long context to answer queries based on real-world academic papers. Extensive experiments on AcademicEval and two other datasets validate that Thought-Retriever remarkably outperforms state-of-the-art baselines by achieving a 5%-45% higher win rate. More importantly, we further demonstrate 2 exciting findings: (1) Thought-Retriever can indeed help LLM self-evolve after solving more user queries; (2) Thought-Retriever learns to leverage deeper thoughts to answer more abstract user queries

          </p>
        </div>

        <!-- <div class="content">
          <div class=" has-text-centered">
            <img src="static/images/figure2.png" alt="MY ALT TEXT"/>
          </div>
          <b class="subtitle is-size-6">
            Thought-Retriever Framework. (a) Thought retrieval: Upon receiving a user query, Thought-Retriever retrieves top-K data
            chunks from the mixture of external knowledge and thought memory based on embedding similarity; (b) Answer generation: The LLM generates the answer for the user query based on the retrieved data chunks; (c) Thought generation: The LLM further generates thought and its confidence based on the user query and the generated answer; (d) Thought memory update: Meaningless and redundant thoughts are removed and the remaining novel thoughts are used to update the thought memory. 
          </b>
        </div> -->

      </div>
    </div>
  </div>
</section>



<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">1. Motivation</h2>
        <div class="content">
          <div class=" has-text-centered">
            <img src="static/images/Motivation.png" alt="MY ALT TEXT"/>
          </div>
          <b class="subtitle is-size-6">
          </b>
        </div>

        <h2 class="title is-4"></h2>
        <div class="content has-text-justified">
          <p>
            
          </p>
        </div>
        
        <div class="content has-text-justified">
          <p>
            Put more content about motivation here ...
          </p>
        </div>

        
        
      </div>
    </div>
  </div>
</section>

<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">2. The Thought-Retrievers Framework</h2>
        <div class="content">
          <div class=" has-text-centered">
            <img src="static/images/figure2.png" alt="MY ALT TEXT"/>
          </div>
          <b class="subtitle is-size-6">
            Thought-Retriever Framework: (a) Thought retrieval: Upon receiving a user query, Thought-Retriever retrieves top-K data
            chunks from the mixture of external knowledge and thought memory based on embedding similarity; (b) Answer generation: The LLM generates the answer for the user query based on the retrieved data chunks; (c) Thought generation: The LLM further generates thought and its confidence based on the user query and the generated answer; (d) Thought memory update: Meaningless and redundant thoughts are removed and the remaining novel thoughts are used to update the thought memory. 
          </b>
        </div>

        <h2 class="title is-4">a) Thought retrieval</h2>
        <div class="content has-text-justified">
          <p>
            After receiving a user query \(Q_i\), Thought-Retriever \(R\) retrieves relevant information \(T_i\) from
            external knowledge \(K\) and previously generated thought
            memory \(T\) via embedding similarity ranking. This process
            is formulated as \(T_i \leftarrow R(Q_i, K \cup T)\).
          </p>
        </div>

        <h2 class="title is-4">b) Answer Generation</h2>
        <div class="content has-text-justified">
          <p>
            Based on the retrieved information \( \mathcal{T}_{i} \), we design a prompt to combine \( \mathcal{T}_{i} \) and user query \( Q_i \) and feed the prompt to an LLM \( L \) to get the answer \( A_i \). It can be articulated as 
    \( A_i \gets L(Q_i, \mathcal{T}_{i}) \).
          </p>
        </div>
        <h2 class="title is-4">c) Thought Generation</h2>
        <div class="content has-text-justified">
          <p>
            We can generate thoughts via LLM \( L \) using the obtained answer \( A_i \) and its query \( Q_i \). However, redundant or meaningless thoughts during the generation process may harm the LLM performance. To solve this issue, we design a special prompt so that LLM \( L \) can generate thoughts \( T_i \) and thought quality confidence \( c_i \) based on the user's query \( Q_i \) and corresponding answer \( A_i \). This can be described as \( T_i, c_i \gets L(Q_i, A_i) \).
          </p>
        </div>
        <h2 class="title is-4">d) Thought Memory Update</h2>
        <div class="content has-text-justified">
          <p>
            The confidence of thought quality \(c_i\) is a boolean indicator that determines whether the newly generated thought should be updated into the thought memory \(\mathcal{T}\). Here, we design that if the LLM is confident about its answer, where \(c_i\) is True, \(\mathcal{T}\) will be updated.
          </p>
        </div>

      </div>
    </div>
  </div>
</section>


<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">3. AcademicEval Benchmark</h2>
        <div class="content">
          <div class="content has-text-justified">
            <p>
              Current benchmarks for assessing agent long-context mem-
              ory utilization involve tasks such as question-answering,
              long-context summarization, and classification. Despite
              being well-constructed, they are limited in flexibility and
              real-world impact and are costly to acquire. To address these
              issues, we introduce an innovative benchmark, AcademicE-
              val, based on academic papers from arXiv collected on a
              weekly basis. AcademicEval is superior in three aspects:
              1) it dynamically collects the most up-to-date data; 2) it
              acquires high-quality labels at no additional cost; and 3)
              it allows real-world applications with high impacts. Aca-
              demicEval comes with two datasets: abstract and related.
  
            </p>

            <p>
              More content will be added soon ...
  
            </p>

       
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">3. AcademicEval Benchmark</h2>
        <div class="content has-text-justified">
          <p>
            More content here ...
          </p>
        </div> -->
        <!-- <div class="container is-max-desktop" style="margin-bottom: 20px;">  
          <div class="columns">  
              <div class="column is-5">
                  <div class="image">    
                      <img src="static/images/working.png" alt="Image 1"> 
                    </div> 
                  <p style="margin: 10px 0;" class="subtitle is-6 has-text-centered">(a) Configurator</p>  
              </div>
              <div class="column is-1">
            </div>  
              <div class="column is-6">  
                  <div class="image">  
                      <img src="static/images/example.png"  alt="Image 2">  
                  </div>  
                  <p style="margin: 10px 0;" class="subtitle is-6 has-text-centered">(b) A running example</p>  
              </div>  
          </div>  
      </div>   -->
      <!-- Removed the Self-Directed Learning paragraph -->
    <!-- </div>
  </div>
</section> -->

<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">4. Experiments</h2>
        <h2 class="title is-4">4.1 Main Results</h2>
        <div class="content has-text-justified">
          <p>
            Add more content about main results here ....
          </p>
        </div>
        <div class="content">
          <div class=" has-text-centered">
            <img src="static/images/Main_results.png"  alt="MY ALT TEXT"/>
          </div>
  
        </div>
      

        <h2 class="title is-4">4.2 new Findings from Thought Retriever</h2>
        <div class="content has-text-justified">
          <p>
            Add content here ....
          </p>
        </div>

        <h2 class="title is-5">(a) Self-evolve</h2>
        <div class="content has-text-justified">
          <p>
            Adding Explanations .....
          </p>
        </div>

        <h2 class="title is-5"> (b) Deeper thoughts help abstract queries </h2>
        <div class="content has-text-justified">
          <p>
            Adding Explanations..........
          </p>
        </div>

        <div class="content">
          
          
        </div>
        <h2 class="title is-5">QUALITATIVE ANALYSIS</h2>
        <div class="container is-max-desktop" style="margin-bottom: 20px;">  
          <div class="columns">  
              <div class="column is-6">
                  <div class="image">    
                      <img src="static/images/self_evolve.png" alt="Image 1"> 
                    </div> 
                  <p style="margin: 10px 0;" class="subtitle is-6 has-text-centered"><b> (a) Self-evolve</b> </p>  
                  <!-- This figure illustrate the agent's performanc across various datasets as the number of thoughts increases -->
              </div>
              <div class="column is-0.5">
              </div>  
              <div class="column is-6">
                <div class="image">    
                  <img src="static/images/deepth_abs.png" alt="Image 1"> 
                </div> 
              <p style="margin: 10px 0;" class="subtitle is-6 has-text-centered"> <b> (b) Deeper thoughts help abstract queries </b></p>  
              <!-- This figure il-
                lustrates the correlation between six questions, categorized by their
                level of abstraction as evaluated by GPT-4 (x-axis), and the abstraction level of the corresponding retrieved information (y-axis). -->
              </div>  
          </div>  

          

  
          
        </div> 
        <div class="content has-text-justified">
          <p>
            More Content here....
          </p>
          
        </div>

        <h2 class="title is-4">4.3 Ablation Study</h2>
        <div class="content has-text-justified">
          <p>
            Add more content about main results here ....
          </p>
        </div>
        <div class="content">
          <div class=" has-text-centered">
            <img src="static/images/Main_results.png"  alt="MY ALT TEXT"/>
          </div>
  
        </div>
   

      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        Your image here
        <img src="static/images/carousel1.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          First image description.
        </h2>
      </div>
      <div class="item">
        Your image here
        <img src="static/images/carousel2.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Second image description.
        </h2>
      </div>
      <div class="item">
        Your image here
        <img src="static/images/carousel3.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
         Third image description.
       </h2>
     </div>
     <div class="item">
       Your image here
      <img src="static/images/carousel4.jpg" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Fourth image description.
      </h2>
    </div>
  </div>
</div>
</div>
</section> -->
<!-- End image carousel -->




<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
       Paper video.
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            Youtube embed code here
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            
            <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            
            <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            
            <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->






<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->

<section class="section">
  <div class="container is-max-desktop content">
        <h2 class="title">Community</h2>
        <div class="content has-text-justified">
          <p>
            Join our community to connect with other agent enthusiasts, share your tools and demos, and collaborate on exciting initiatives. You can find us on <a href="https://join.slack.com/t/slack-ped8294/shared_invite/zt-2cqebow90-soac9UFKGZ2RcUy8PqjZrA" target="_blank" >Slack</a>.
          </p>
       
      </div>
  </div>
</section>
<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
        
        @misc{wu2024oscopilot,
          title={OS-Copilot: Towards Generalist Computer Agents with Self-Improvement}, 
          author={Zhiyong Wu and Chengcheng Han and Zichen Ding and Zhenmin Weng and Zhoumianze Liu and Shunyu Yao and Tao Yu and Lingpeng Kong},
          year={2024},
          eprint={2402.07456},
          archivePrefix={arXiv},
          primaryClass={cs.AI}
        }

      </code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
